# the dataset will consist of all audio files found in a particular directory
# tree; for training and validation, it will be limited to those occurring in
# one of the training csv files, split according to a particular scheme

# directory of audio files, can be absolute or relative to this config file
data.audio_dir=audio
# regular expression for selecting audio files to consider (acts on full path)
data.audio_regexp=.*\.wav
# official training csv
data.train_csv=data/openmic-2018.npz
data.label-map=data/class-map.json

# train/validation split: stratified or byrecordist
data.split_mode=byrecordist
data.split_seed=1
data.valid_size=4000

# class-based sampling: equal, roundrobin, or a comma-separated list of weights
data.class_sample_weights=

# downmixing to mono: average, random_uniform or none
data.downmix=average

# input block length (in seconds, set both to 0 to use full recordings)
data.len_min=10
data.len_max=10
# number of buckets between min and max length for bucketed mini-batches
data.len_buckets=10

# default metrics
metrics=_ce:multilabel_crossentropy,acc:multilabel_accuracy,prec:binary_precision,rec:binary_recall,ptrue:cnt_pred_true,gt_true:cnt_gt_true,pfalse:cnt_pred_false,gt_false:cnt_gt_false
metrics._ce.ignore=255
metrics.acc.ignore=255
metrics.multilabel_*.target_name=label_all
metrics.binary_*.target_name=label_all
metrics.cnt_*.target_name=label_all
loss=_ce